import streamlit as st
from groq import Groq
from typing import Generator

# Configuraci贸n de la p谩gina de Streamlit
st.set_page_config(page_title="Nexy", page_icon="", layout="wide")
st.title("Nexy ")

# Inicializaci贸n del cliente Groq con la API Key
client = Groq(
    api_key="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"
)

# Modelos disponibles en Groq
modelos = ['gemma-7b-it']

# Informaci贸n b谩sica que Groq puede usar
basic_info = """
Aqu铆 tienes la traducci贸n al espa帽ol:

Nexy es el asistente personal de Maria Jose Mu帽oz Leon, estudiante de Ingenier铆a Mecatr贸nica en la Universidad Militar Nueva Granada. Maria Jose es cofundadora y CTO de Lean Build, una startup enfocada en la construcci贸n dedicada a optimizar los flujos de trabajo para gerentes de proyectos y supervisores de obras dentro del entorno de la construcci贸n. 

Adem谩s, Maria Jose cofund贸 UNDAM, una f谩brica de software que cre贸 junto con tres amigos de la universidad: Robert Castro, Jose Rincon y Juan Avid Duran. UNDAM ha conseguido clientes en Am茅rica del Norte, Central y del Sur, ofreciendo servicios de consultor铆a tecnol贸gica, desarrollo de software a la medida, creaci贸n de bots, desarrollo de modelos de IA para la optimizaci贸n de negocios y automatizaci贸n de procesos.

Maria Jose tambi茅n forma parte de Makers, un programa de becas exclusivo en el que solo ingresa el 1% de los solicitantes de toda Am茅rica Latina. A principios de 2025, comenzar谩 una pasant铆a en Bavaria en el departamento de an谩lisis de datos e inteligencia artificial. Su experiencia t茅cnica incluye s贸lidas habilidades en Python, C++, estructuras de datos, aprendizaje autom谩tico y aprendizaje profundo, as铆 como en desarrollo frontend y backend, infraestructura en la nube, Java, JavaScript, React, Flutter, Flask, MongoDB, SQL, AWS, GCP, LLMs y gesti贸n de bases de datos en m煤ltiples servicios. Habla con fluidez ingl茅s, espa帽ol y franc茅s y cuenta con certificaciones de IBM en IA y habilidades blandas. Su informaci贸n de contacto es la siguiente: Instagram @majo_munozl, LinkedIn MARIA JOSE Mu帽oz Leon y m贸vil +57 310 754 5406.
"""

# Funci贸n generadora para mostrar las respuestas del asistente
def generate_chat_responses(chat_completion) -> Generator[str, None, None]:   
    """Genera respuestas a partir de los chunks del chat_completion de Groq."""
    for chunk in chat_completion:
        if hasattr(chunk.choices[0], 'delta') and hasattr(chunk.choices[0].delta, 'content'):
            yield chunk.choices[0].delta.content

# Inicializar estado de la sesi贸n para mensajes
if "messages" not in st.session_state:
    st.session_state.messages = []

# Mensaje inicial del sistema proporcionando el contexto del asistente con la informaci贸n b谩sica
if not st.session_state.messages:
    system_message = {
        "role": "system",
        "content": (
        "Nexy, eres el asistente personal de Maria Jose Mu帽oz Leon. Saluda a los usuarios present谩ndote como su asistente personal. Responde siempre en el idioma en el que la persona te escriba. No tienes permitido responder preguntas que involucren informaci贸n sensible, como la direcci贸n de residencia de Maria Jose, sus relaciones personales o temas de 铆ndole sexual. Solo puedes proporcionar su n煤mero de m贸vil (+57 310 754 5406), Instagram (@majo_munozl) y LinkedIn (Maria Jose Mu帽oz Leon) cuando te lo soliciten, el resto e informacion la puedes dar ya que se te proporciono en basic info"    }
    st.session_state.messages.append(system_message)

# Mostrar los mensajes de chat previos del usuario y el asistente en la aplicaci贸n
with st.container():
    for message in st.session_state.messages:
        if message["role"] != "system":  # Evitar mostrar el mensaje del sistema
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

# Campo de entrada para el prompt del usuario
prompt = st.chat_input("驴Que te gustaria saber de majo el dia de hoy?")

if prompt:
    # Mostrar mensaje del usuario en el contenedor de mensajes de chat
    st.chat_message("user").markdown(prompt)
    # Agregar mensaje del usuario al historial de chat
    st.session_state.messages.append({"role": "user", "content": prompt})
    
    try:
        # Generar respuesta con Groq usando el historial de mensajes, incluyendo el mensaje inicial con la informaci贸n b谩sica
        chat_completion = client.chat.completions.create(
            model=modelos[0],  # Aseg煤rate de seleccionar el modelo correcto                      
            messages=[
                {"role": m["role"], "content": m["content"]}
                for m in st.session_state.messages
            ],  # Entregamos el historial de los mensajes para que el modelo tenga contexto
            stream=True
        )

        # Generar respuestas con el contenido correcto desde los chunks de Groq
        response_chunks = [
            chunk.choices[0].delta.content
            for chunk in chat_completion 
            if hasattr(chunk.choices[0], 'delta') and hasattr(chunk.choices[0].delta, 'content') and chunk.choices[0].delta.content is not None
        ]

        response_content = "".join(response_chunks)

    except Exception as e:
        st.error(f"Error con Groq: {e}")
        response_content = "Lo siento, hubo un problema al procesar la solicitud."

    # Mostrar la respuesta final
    with st.chat_message("assistant"):
        st.markdown(response_content)

    # Agregar respuesta del asistente al historial de chat
    st.session_state.messages.append({"role": "assistant", "content": response_content})
